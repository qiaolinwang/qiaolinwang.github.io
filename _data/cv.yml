- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Qiaolin Wang
    - name: Email
      value: <a href="mailto:qw2443@columbia.edu">qw2443@columbia.edu</a>
    - name: Location
      value: New York, USA
    - name: Research Interests
      value: Speech LLMs, multimodal fusion, emotion recognition, human-centered audio AI

- title: Education
  type: time_table
  contents:
    - title: M.S. Electrical Engineering
      institution: Columbia University, New York, NY
      year: 2024 - Present
      description:
        - Coursework in speech processing, machine learning theory, and multimodal systems.
        - Research on audio-language modeling and cross-modal reasoning.
    - title: B.Eng. Computer Science and Engineering
      institution: Wuhan University, Wuhan, China
      year: 2020 - 2024
      description:
        - Built speech-driven applications and intelligent user experiences.
        - Led collaborative student teams focused on audio AI and interactive media.

- title: Research Experience
  type: time_table
  contents:
    - title: Graduate Researcher, Speech & Multimodal Intelligence
      institution: Columbia University
      year: 2024 - Present
      description:
        - Co-developing SightSound-R1, distilling reasoning from vision-language foundation models into audio-language agents.
        - Layer-wise probing of self-supervised speech representations to uncover grammatical and conceptual hierarchies.
    - title: Student Researcher, Wuhan University
      institution: Wuhan University, Wuhan, China
      year: 2022 - 2024
      description:
        - Prototyped emotion-aware dialogue systems with interdisciplinary student teams.
        - Curated open-source toolkits to streamline speech model experimentation and evaluation.

- title: Publications
  type: time_table
  contents:
    - title: Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations
      year: 2025
      description:
        - EMNLP 2025 Oral. With Lucy He, Xuan Jiang, and Nima Mesgarani.
    - title: "SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models"
      year: 2025
      description:
        - arXiv preprint 2509.15661. With Xuan Jiang, Lucy He, Jiatong Wu, and Nima Mesgarani.

- title: Selected Projects
  type: time_table
  contents:
    - title: ChatVITS_Cyberpunk2077
      year: 2023
      description:
        - Combined GPT-based dialogue planning with VITS voice cloning to create responsive Cyberpunk 2077 character performances.
        - Open-sourced training scripts, dataset handling, and inference demos for creative voice synthesis.
    - title: Audio Signal Processing Toolkit
      year: 2022
      description:
        - Authored a hands-on repository covering feature engineering, PyTorch training loops, and visualization utilities for speech ML.
        - Shared as support material for audio signal processing courses and study groups.
    - title: Reinforcement Learning-based Stock Trading Agent
      year: 2021
      description:
        - Explored DQN, DDPG, and A2C baselines for algorithmic trading in the ELEN6885 Advanced Machine Learning course.
        - Implemented custom reward shaping and evaluation dashboards for risk-aware deployment.

- title: Skills
  type: list
  contents:
    - Machine Learning: PyTorch, TensorFlow, scikit-learn, Hugging Face Transformers
    - Audio & Speech: torchaudio, ESPnet, speech representation learning, TTS pipelines
    - Languages: English, Mandarin Chinese
    - Creative: Hip-hop music production, sound design, live performance
